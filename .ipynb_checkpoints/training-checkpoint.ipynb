{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0ec7783-45f0-459f-af55-ab8043a11d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: AMD currently is not stable with 4bit bitsandbytes. Disabling for now.\n",
      "==((====))==  Unsloth 2025.10.9: Fast Qwen2 patching. Transformers: 4.56.2. vLLM: 0.11.1rc3.dev39+gf417746ad.rocm700.\n",
      "   \\\\   /|    . Num GPUs = 1. Max memory: 255.688 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.0a0+git1c57644. ROCm Toolkit: 7.0.51831-a3e329ad8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ffcecc41c9949d9aa4b71270eaaed08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.10.9 patched 48 layers with 48 QKV layers, 48 O layers and 48 MLP layers.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
      "We will change the batch size of 1 to the `num_generations` of 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 3 | Num Epochs = 4 | Total steps = 10\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 1 x 1) = 2\n",
      " \"-____-\"     Trainable parameters = 34,406,400 of 14,804,440,064 (0.23% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:47, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>reward</th>\n",
       "      <th>reward_std</th>\n",
       "      <th>completions / mean_length</th>\n",
       "      <th>completions / min_length</th>\n",
       "      <th>completions / max_length</th>\n",
       "      <th>completions / clipped_ratio</th>\n",
       "      <th>completions / mean_terminated_length</th>\n",
       "      <th>completions / min_terminated_length</th>\n",
       "      <th>completions / max_terminated_length</th>\n",
       "      <th>sampling / sampling_logp_difference / mean</th>\n",
       "      <th>sampling / sampling_logp_difference / max</th>\n",
       "      <th>sampling / importance_sampling_ratio / min</th>\n",
       "      <th>sampling / importance_sampling_ratio / mean</th>\n",
       "      <th>sampling / importance_sampling_ratio / max</th>\n",
       "      <th>kl</th>\n",
       "      <th>rewards / reward_valid_json / mean</th>\n",
       "      <th>rewards / reward_valid_json / std</th>\n",
       "      <th>rewards / reward_answer_format / mean</th>\n",
       "      <th>rewards / reward_answer_format / std</th>\n",
       "      <th>rewards / reward_explanation_length / mean</th>\n",
       "      <th>rewards / reward_explanation_length / std</th>\n",
       "      <th>rewards / reward_answer_correctness / mean</th>\n",
       "      <th>rewards / reward_answer_correctness / std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>131.500000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>131.500000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>128.500000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>128.500000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.003699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>142.500000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>142.500000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.011095</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.007963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>146.500000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>146.500000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.008826</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.033648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GRPO training pipeline for Q-agent: generate JSON (topic, question, choices, answer, explanation).\n",
    "Uses a 3-row sanity dataset; replace with your full dataset for real training.\n",
    "\"\"\"\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from datasets import Dataset\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1. Sanity dataset: 3 rows in your JSON format\n",
    "# ---------------------------------------------------------------------------\n",
    "RAW_DATA = [\n",
    "    {\n",
    "        \"topic\": \"Alphanumeric Series\",\n",
    "        \"question\": \"What comes next in the series: A1, B2, C3, D4, ?\",\n",
    "        \"choices\": [\n",
    "            \"A) E5\",\n",
    "            \"B) F6\",\n",
    "            \"C) D5\",\n",
    "            \"D) E4\",\n",
    "        ],\n",
    "        \"answer\": \"A\",\n",
    "        \"explanation\": \"The pattern is one letter and one number each increasing by 1. So next is E5.\",\n",
    "    },\n",
    "    {\n",
    "        \"topic\": \"Number Series\",\n",
    "        \"question\": \"Next number in sequence: 2, 6, 12, 20, 30, ?\",\n",
    "        \"choices\": [\n",
    "            \"A) 40\",\n",
    "            \"B) 42\",\n",
    "            \"C) 44\",\n",
    "            \"D) 36\",\n",
    "        ],\n",
    "        \"answer\": \"B\",\n",
    "        \"explanation\": \"Differences are 4, 6, 8, 10 (even numbers). Next difference is 12, so 30 + 12 = 42.\",\n",
    "    },\n",
    "    {\n",
    "        \"topic\": \"Logical Reasoning\",\n",
    "        \"question\": \"If all roses are flowers and some flowers fade quickly, which must be true?\",\n",
    "        \"choices\": [\n",
    "            \"A) All roses fade quickly\",\n",
    "            \"B) Some roses may fade quickly\",\n",
    "            \"C) No roses fade quickly\",\n",
    "            \"D) All flowers are roses\",\n",
    "        ],\n",
    "        \"answer\": \"B\",\n",
    "        \"explanation\": \"Some flowers fade quickly; roses are a subset of flowers. So some roses may be in that subset.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are a Q-agent. Given a topic, output exactly one JSON object with no other text.\n",
    "Use this format only:\n",
    "{\"topic\": \"<Topic>\", \"question\": \"<full question>\", \"choices\": [\"A) ...\", \"B) ...\", \"C) ...\", \"D) ...\"], \"answer\": \"<A or B or C or D>\", \"explanation\": \"<brief explanation, at most 100 words>\"}\"\"\"\n",
    "\n",
    "\n",
    "def build_grpo_dataset(raw_rows):\n",
    "    \"\"\"Convert list of JSON-format items to GRPO dataset with chat prompts.\"\"\"\n",
    "    prompts = []\n",
    "    answers = []\n",
    "    for item in raw_rows:\n",
    "        topic = item[\"topic\"]\n",
    "        user_content = f\"Generate a single multiple-choice question in the required JSON format for the topic: {topic}.\"\n",
    "        prompts.append([\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_content},\n",
    "        ])\n",
    "        answers.append(item[\"answer\"].strip().upper())\n",
    "    return Dataset.from_dict({\"prompt\": prompts, \"answer\": answers})\n",
    "\n",
    "\n",
    "dataset = build_grpo_dataset(RAW_DATA)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2. Model and LoRA\n",
    "# ---------------------------------------------------------------------------\n",
    "lora_rank = 8\n",
    "# Use a small model for pipeline sanity; switch to 14B for real training.\n",
    "model_path = os.environ.get(\"GRPO_MODEL_PATH\", \"/workspace/AAIPL/hf_models/Qwen2.5-14B-Instruct\")\n",
    "max_seq_length = 1024\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_path,\n",
    "    max_seq_length=max_seq_length,\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=lora_rank,\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha=lora_rank * 2,\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=3407,\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3. Lengths and GRPO config\n",
    "# ---------------------------------------------------------------------------\n",
    "max_prompt_length = 256\n",
    "max_completion_length = max_seq_length - max_prompt_length\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    temperature=1.0,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.001,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    optim=\"adamw_8bit\",\n",
    "    logging_steps=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_generations=2,\n",
    "    max_prompt_length=max_prompt_length,\n",
    "    max_completion_length=max_completion_length,\n",
    "    max_steps=10,\n",
    "    save_steps=10,\n",
    "    report_to=\"none\",\n",
    "    output_dir=\"outputs\",\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 4. Reward functions (signature: prompts, completions, answer, **kwargs)\n",
    "#    Completions are list of [{\"role\":\"assistant\",\"content\": \"...\"}]; we use content.\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def get_content(completion):\n",
    "    if isinstance(completion, str):\n",
    "        return completion\n",
    "    if isinstance(completion, (list, tuple)) and completion and isinstance(completion[0], dict):\n",
    "        return completion[0].get(\"content\", \"\")\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def reward_valid_json(completions, **kwargs):\n",
    "    scores = []\n",
    "    for c in completions:\n",
    "        text = get_content(c)\n",
    "        try:\n",
    "            # Allow JSON inside markdown code blocks\n",
    "            if \"```\" in text:\n",
    "                text = re.search(r\"```(?:json)?\\s*([\\s\\S]*?)```\", text)\n",
    "                text = text.group(1).strip() if text else text\n",
    "            data = json.loads(text.strip())\n",
    "            required = {\"topic\", \"question\", \"choices\", \"answer\", \"explanation\"}\n",
    "            if required.issubset(data.keys()) and isinstance(data.get(\"choices\"), list) and len(data[\"choices\"]) == 4:\n",
    "                scores.append(1.0)\n",
    "            else:\n",
    "                scores.append(0.0)\n",
    "        except (json.JSONDecodeError, TypeError, AttributeError):\n",
    "            scores.append(0.0)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def reward_answer_format(completions, **kwargs):\n",
    "    scores = []\n",
    "    for c in completions:\n",
    "        text = get_content(c)\n",
    "        try:\n",
    "            if \"```\" in text:\n",
    "                m = re.search(r\"```(?:json)?\\s*([\\s\\S]*?)```\", text)\n",
    "                text = m.group(1).strip() if m else \"\"\n",
    "            data = json.loads(text.strip())\n",
    "            ans = (data.get(\"answer\") or \"\").strip().upper()\n",
    "            scores.append(1.0 if ans in (\"A\", \"B\", \"C\", \"D\") else 0.0)\n",
    "        except (json.JSONDecodeError, TypeError, AttributeError):\n",
    "            scores.append(0.0)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def reward_explanation_length(completions, **kwargs):\n",
    "    scores = []\n",
    "    for c in completions:\n",
    "        text = get_content(c)\n",
    "        try:\n",
    "            if \"```\" in text:\n",
    "                m = re.search(r\"```(?:json)?\\s*([\\s\\S]*?)```\", text)\n",
    "                text = m.group(1).strip() if m else \"\"\n",
    "            data = json.loads(text.strip())\n",
    "            expl = (data.get(\"explanation\") or \"\")\n",
    "            n = len(expl.split())\n",
    "            scores.append(1.0 if 0 < n <= 100 else (0.5 if n <= 100 else 0.0))\n",
    "        except (json.JSONDecodeError, TypeError, AttributeError):\n",
    "            scores.append(0.0)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def reward_answer_correctness(prompts, completions, answer, **kwargs):\n",
    "    \"\"\"Reward when generated 'answer' matches the reference (dataset) answer.\"\"\"\n",
    "    if answer is None:\n",
    "        return [0.0] * len(completions)\n",
    "    refs = answer if isinstance(answer, (list, tuple)) else [answer]\n",
    "    if len(refs) < len(completions):\n",
    "        refs = (refs * ((len(completions) // len(refs)) + 1))[:len(completions)]\n",
    "    scores = []\n",
    "    for c, ref in zip(completions, refs):\n",
    "        text = get_content(c)\n",
    "        ref = (ref or \"\").strip().upper()\n",
    "        try:\n",
    "            if \"```\" in text:\n",
    "                m = re.search(r\"```(?:json)?\\s*([\\s\\S]*?)```\", text)\n",
    "                text = m.group(1).strip() if m else \"\"\n",
    "            data = json.loads(text.strip())\n",
    "            ans = (data.get(\"answer\") or \"\").strip().upper()\n",
    "            scores.append(2.0 if ans == ref else 0.0)\n",
    "        except (json.JSONDecodeError, TypeError, AttributeError):\n",
    "            scores.append(0.0)\n",
    "    return scores\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 5. Trainer and train\n",
    "# ---------------------------------------------------------------------------\n",
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    reward_funcs=[\n",
    "        reward_valid_json,\n",
    "        reward_answer_format,\n",
    "        reward_explanation_length,\n",
    "        reward_answer_correctness,\n",
    "    ],\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trainer.train()\n",
    "    model.save_pretrained(os.path.join(training_args.output_dir, \"final\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d0e571-c7de-4c4d-8d42-3c39c6dc0b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
